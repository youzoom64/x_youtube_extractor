"""CLIç”¨Twitterå–å¾—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
import logging
from lib.chrome_connector import ChromeConnector
from lib.twitter_scraper import TwitterScraper
from lib.twitter_parser import TwitterParser
from lib.formatter import Formatter
from lib.utils import setup_logging, validate_query

logger = logging.getLogger(__name__)

class ScrapeOnlyWorkflowCLI:
    def __init__(self):
        self.chrome = ChromeConnector()
        self.scraper = None
        self.parser = TwitterParser()
        self.formatter = Formatter()
    
    def execute(self, query, count=20, format_type="txt", sort_type="latest"):
        """Twitterå–å¾—ã®ã¿ã‚’å®Ÿè¡Œï¼ˆCLIç‰ˆï¼‰"""
        logger.info(f"=== Twitterå–å¾—é–‹å§‹ ===")
        logger.info(f"ã‚¯ã‚¨ãƒª: {query}")
        logger.info(f"ä»¶æ•°: {count}")
        logger.info(f"ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: {format_type}")
        logger.info(f"ã‚½ãƒ¼ãƒˆ: {sort_type}")
        
        try:
            # å…¥åŠ›ãƒã‚§ãƒƒã‚¯
            is_valid, error_msg = validate_query(query)
            if not is_valid:
                logger.error(f"å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {error_msg}")
                return None
            
            # Chromeæ¥ç¶š
            if not self.chrome.connect():
                logger.error("Chromeæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")
                return None
            
            self.scraper = TwitterScraper(self.chrome)
            
            # ãƒ„ã‚¤ãƒ¼ãƒˆå–å¾—ï¼ˆã‚½ãƒ¼ãƒˆæŒ‡å®šï¼‰
            if query.startswith('@'):
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ„ã‚¤ãƒ¼ãƒˆå–å¾—ï¼ˆã‚½ãƒ¼ãƒˆæŒ‡å®šãªã—ï¼‰
                raw_tweets = self.scraper.get_user_tweets(query, count)
                logger.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ„ã‚¤ãƒ¼ãƒˆå–å¾—å®Œäº†")
            else:
                # æ¤œç´¢ãƒ„ã‚¤ãƒ¼ãƒˆå–å¾—ï¼ˆã‚½ãƒ¼ãƒˆæŒ‡å®šã‚ã‚Šï¼‰
                raw_tweets = self.scraper.search_tweets(query, count, sort_type)
                logger.info(f"æ¤œç´¢ãƒ„ã‚¤ãƒ¼ãƒˆå–å¾—å®Œäº†ï¼ˆ{sort_type}é †ï¼‰")
            
            if not raw_tweets:
                logger.warning("ãƒ„ã‚¤ãƒ¼ãƒˆãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return None
            
            # ãƒ‡ãƒ¼ã‚¿è§£æ
            logger.info("ãƒ„ã‚¤ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿è§£æä¸­...")
            parsed_tweets = self.parser.parse_tweets(raw_tweets)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            logger.info("ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­...")
            filepath = self.formatter.save_tweets(parsed_tweets, query, format_type)
            
            if filepath:
                logger.info(f"=== å‡¦ç†å®Œäº† ===")
                logger.info(f"ä¿å­˜å…ˆ: {filepath}")
                logger.info(f"å–å¾—ä»¶æ•°: {len(parsed_tweets)}")
                
                # CLIç”¨ã®ç°¡æ½”ãªçµæœè¡¨ç¤º
                print(f"âœ… Twitterå–å¾—å®Œäº†")
                print(f"ğŸ“ ä¿å­˜å…ˆ: {filepath}")
                print(f"ğŸ“Š å–å¾—ä»¶æ•°: {len(parsed_tweets)}ä»¶")
                print(f"ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}")
                print(f"ğŸ“ˆ ã‚½ãƒ¼ãƒˆé †: {sort_type}")
                
                return filepath
            else:
                logger.error("ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
                print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return None
                
        except Exception as e:
            logger.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return None
        finally:
            # Chromeæ¥ç¶šã¯ä¿æŒï¼ˆä»–ã®å‡¦ç†ã§ä½¿ç”¨å¯èƒ½ï¼‰
            pass
    
    def get_stats(self, tweets):
        """å–å¾—ã—ãŸãƒ„ã‚¤ãƒ¼ãƒˆã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
        if not tweets:
            return
        
        total_likes = sum(tweet.get('likes', 0) for tweet in tweets)
        total_reposts = sum(tweet.get('reposts', 0) for tweet in tweets)
        total_replies = sum(tweet.get('replies', 0) for tweet in tweets)
        
        avg_likes = total_likes // len(tweets) if tweets else 0
        avg_reposts = total_reposts // len(tweets) if tweets else 0
        avg_replies = total_replies // len(tweets) if tweets else 0
        
        print(f"ğŸ“Š çµ±è¨ˆæƒ…å ±:")
        print(f"   å¹³å‡ã„ã„ã­æ•°: {avg_likes}")
        print(f"   å¹³å‡ãƒªãƒã‚¹ãƒˆæ•°: {avg_reposts}")
        print(f"   å¹³å‡ãƒªãƒ—ãƒ©ã‚¤æ•°: {avg_replies}")
        print(f"   ç·ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ: {total_likes + total_reposts + total_replies}")
    
    def validate_sort_type(self, sort_type):
        """ã‚½ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        valid_sorts = ["latest", "top"]
        if sort_type not in valid_sorts:
            logger.warning(f"ç„¡åŠ¹ãªã‚½ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—: {sort_type}, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(latest)ã‚’ä½¿ç”¨")
            return "latest"
        return sort_type
    
    def dry_run(self, query, count=5, sort_type="latest"):
        """ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼‰"""
        logger.info(f"=== ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œ ===")
        print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰")
        print(f"ğŸ” ã‚¯ã‚¨ãƒª: {query}")
        print(f"ğŸ“Š ä»¶æ•°: {count}")
        print(f"ğŸ“ˆ ã‚½ãƒ¼ãƒˆ: {sort_type}")
        
        # å°‘æ•°ã®ãƒ„ã‚¤ãƒ¼ãƒˆã§å®Ÿéš›ã«å–å¾—ãƒ†ã‚¹ãƒˆ
        result = self.execute(query, count, "txt", sort_type)
        
        if result:
            print(f"âœ… ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³æˆåŠŸ")
            print(f"ğŸ“ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {result}")
        else:
            print(f"âŒ ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å¤±æ•—")
        
        return result