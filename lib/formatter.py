"""å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†"""
import json
import os
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class Formatter:
    def __init__(self, output_dir="output/query"):
        self.output_dir = output_dir
        self._ensure_output_dir()
    
    def _ensure_output_dir(self):
        """å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        os.makedirs(self.output_dir, exist_ok=True)
   
    def save_with_analysis(self, tweets, analysis, query, format_type="txt"):
        """åˆ†æçµæœä»˜ãã§ä¿å­˜"""
        filename = self._generate_filename(query, format_type, suffix="_analysis")
        filepath = os.path.join(self.output_dir, filename)
        
        if format_type.lower() == "json":
            return self._save_analysis_json(tweets, analysis, query, filepath)
        else:
            return self._save_analysis_txt(tweets, analysis, query, filepath)
    
    def _save_as_txt(self, tweets, query, filepath):
        """TXTå½¢å¼ã§ä¿å­˜"""
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(f"æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}\n")
                f.write(f"å–å¾—æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"å–å¾—ä»¶æ•°: {len(tweets)}\n")
                f.write("=" * 50 + "\n\n")
                
                for tweet in tweets:
                    # çµµæ–‡å­—ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›´
                    f.write(f"æ™‚åˆ»: {tweet.get('datetime', '')}\n")
                    f.write(f"URL: {tweet.get('url', '')}\n")
                    f.write(f"{tweet.get('username', '')}\n")
                    f.write(f"{tweet.get('text', '')}\n")
                    
                    # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆï¼ˆçµµæ–‡å­—ãªã—ï¼‰
                    replies = tweet.get('replies', 0)
                    reposts = tweet.get('reposts', 0)
                    likes = tweet.get('likes', 0)
                    views = tweet.get('views', 0)
                    
                    f.write(f"ãƒªãƒ—ãƒ©ã‚¤: {replies} | ãƒªãƒã‚¹ãƒˆ: {reposts} | ã„ã„ã­: {likes} | è¡¨ç¤º: {views}\n\n")
            
            logger.info(f"TXTãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"TXTä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _save_as_json(self, tweets, query, filepath):
        """JSONå½¢å¼ã§ä¿å­˜"""
        try:
            data = {
                "scrape_info": {
                    "query": query,
                    "timestamp": datetime.now().isoformat(),
                    "count": len(tweets)
                },
                "tweets": tweets
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"JSONãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"JSONä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _save_analysis_txt(self, tweets, analysis, query, filepath):
        """åˆ†æçµæœä»˜ãTXTä¿å­˜"""
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(f"æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}\n")
                f.write(f"å–å¾—æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"å–å¾—ä»¶æ•°: {len(tweets)}\n")
                f.write("=" * 50 + "\n\n")
                
                # åˆ†æçµæœ
                f.write("ã€Claudeåˆ†æçµæœã€‘\n")
                f.write(f"{analysis}\n")
                f.write("=" * 50 + "\n\n")
                
                # ãƒ„ã‚¤ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
                f.write("ã€å–å¾—ãƒ‡ãƒ¼ã‚¿ã€‘\n")
                for tweet in tweets:
                    f.write(f"æ™‚åˆ»: {tweet.get('datetime', '')}\n")
                    f.write(f"URL: {tweet.get('url', '')}\n")
                    f.write(f"{tweet.get('username', '')}\n")
                    f.write(f"{tweet.get('text', '')}\n")
                    
                    replies = tweet.get('replies', 0)
                    reposts = tweet.get('reposts', 0)
                    likes = tweet.get('likes', 0)
                    views = tweet.get('views', 0)
                    
                    f.write(f"ãƒªãƒ—ãƒ©ã‚¤: {replies} | ãƒªãƒã‚¹ãƒˆ: {reposts} | ã„ã„ã­: {likes} | è¡¨ç¤º: {views}\n\n")
            
            logger.info(f"åˆ†æçµæœä»˜ãTXTãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"åˆ†æTXTä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _save_analysis_json(self, tweets, analysis, query, filepath):
        """åˆ†æçµæœä»˜ãJSONä¿å­˜"""
        try:
            data = {
                "scrape_info": {
                    "query": query,
                    "timestamp": datetime.now().isoformat(),
                    "count": len(tweets)
                },
                "analysis": analysis,
                "tweets": tweets
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"åˆ†æçµæœä»˜ãJSONãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"åˆ†æJSONä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _generate_filename(self, query, format_type, suffix=""):
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰"""
        from lib.utils import sanitize_filename
        import datetime
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆ
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ã‚¯ã‚¨ãƒªã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚º
        safe_query = sanitize_filename(query)
        
        # æ‹¡å¼µå­
        ext = "json" if format_type.lower() == "json" else "txt"
        
        return f"{timestamp}_{safe_query}{suffix}.{ext}"

    def _ensure_output_dir(self):
        """å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ä»˜ãï¼‰"""
        import datetime
        
        # æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
        today = datetime.datetime.now().strftime("%Y-%m-%d")
        self.daily_dir = os.path.join(self.output_dir, today)
        
        os.makedirs(self.daily_dir, exist_ok=True)
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.daily_dir}")

    def save_tweets(self, tweets, query, format_type="txt"):
        """ãƒ„ã‚¤ãƒ¼ãƒˆã‚’ä¿å­˜"""
        filename = self._generate_filename(query, format_type)
        filepath = os.path.join(self.daily_dir, filename)  # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜
        
        if format_type.lower() == "json":
            return self._save_as_json(tweets, query, filepath)
        else:
            return self._save_as_txt(tweets, query, filepath)

    def save_with_analysis(self, tweets, analysis, query, format_type="txt"):
        """åˆ†æçµæœä»˜ãã§ä¿å­˜"""
        filename = self._generate_filename(query, format_type, suffix="_analysis")
        filepath = os.path.join(self.daily_dir, filename)  # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜
        
        if format_type.lower() == "json":
            return self._save_analysis_json(tweets, analysis, query, filepath)
        else:
            return self._save_analysis_txt(tweets, analysis, query, filepath)